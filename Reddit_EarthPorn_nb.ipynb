{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.filelist import findall\n",
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import spacy_udpipe\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreiving posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pushshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = int(dt.datetime.timestamp(dt.datetime.strptime('2011-02-14 00:00:00', '%Y-%m-%d %H:%M:%S'))) #time EarthPorn was created\n",
    "end_time = int(dt.datetime.timestamp(dt.datetime.strptime('2023-02-28 00:00:00', '%Y-%m-%d %H:%M:%S')))\n",
    "current_time = int(dt.datetime.timestamp(dt.datetime.now()))\n",
    "\n",
    "# Create string specifying time frame that can be used for file name when saving data as csv\n",
    "search_time = '20110214-20220816' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify subreddit and search limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set subreddit and limit\n",
    "subreddit = 'EarthPorn'\n",
    "limit = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query posts from pushshift using search_submissions with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default parameters:  \n",
    "max_ids_per_request = 500 (max)  \n",
    "max_results_per_request = 100 (max)  \n",
    "mem_safe = False -> stores responses in cache during operation if True  \n",
    "safe_exit = False -> will safely exit if interupted by storing current responses and requests in the cache if True  \n",
    "cache_dir -> path to cache responses in when mem_safe or safe_exit is enabled  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = api.search_submissions(subreddit=subreddit, limit=limit, before=current_time, after=start_time)\n",
    "print(f'Retrieved {len(posts)} posts from Pushshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data frame for posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list = [post for post in posts]\n",
    "posts_df = pd.DataFrame(post_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview sample of posts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_row', 25)\n",
    "print(posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get list of all column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.drop(columns = ['author_flair_css_class', 'author_flair_text'], inplace = True)\n",
    "\n",
    "#posts_df.drop(columns = ['author_flair_css_class', 'author_flair_text', 'gilded', 'mod_reports', 'user_reports', 'brand_safe', 'contest_mode', 'spoiler', 'suggested_sort', 'author_flair_richtext', 'author_flair_type', 'can_mod_post', 'link_flair_richtext', 'link_flair_text_color', 'link_flair_type', 'rte_mode', 'subreddit_type', 'thumbnail_height', 'thumbnail_width', 'author_flair_background_color', 'author_flair_text_color', 'author_patreon_flair', 'gildings', 'is_robot_indexable', 'link_flair_background_color', 'send_replies', 'no_follow', 'updated_utc', 'all_awardings', 'allow_live_comments', 'author_premium', 'awarders', 'total_awards_received', 'treatment_tags', 'is_created_from_ads_ui', 'parent_whitelist_status', 'pwls', 'url_overridden_by_dest', 'whitelist_status', 'wls', 'removed_by_category', 'author_is_blocked', 'approved_at_utc', 'banned_at_utc', 'steward_reports', 'removed_by', 'poll_data', 'top_awarded_type', 'retrieved_on'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change column names and reorder columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create dictionary - 'old name' : 'new name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'id' : 'PostID',\n",
    "                'subreddit' : 'Subreddit',\n",
    "                'subreddit_id' : 'SubredditID',\n",
    "                'created_utc' : 'PostTime',\n",
    "                'title' : 'PostTitle',\n",
    "                'author' : 'Username',\n",
    "                'author_created_utc' : 'UserCreatedTime',\n",
    "                'author_fullname' : 'AuthorName', \n",
    "                'domain' : 'ImageDomain',\n",
    "                'full_link' : 'Link',\n",
    "                'is_self' : 'IsTextPost',\n",
    "                'media_embed' : 'EmbeddedMedia',\n",
    "                'secure_media_embed' : 'SecureEmbeddedMedia',\n",
    "                'num_comments' : 'CommentNumber', \n",
    "                'over_18' : 'NSFW',\n",
    "                'permalink' : 'Permalink', \n",
    "                'score' : 'Upvotes', \n",
    "                'selftext' : 'PostText', \n",
    "                'thumbnail' : 'Thumbnail',\n",
    "                'url' : 'ImageURL',\n",
    "                'media' : 'Media',\n",
    "                'secure_media' : 'SecureMedia',\n",
    "                'stickied' : 'Stickied',\n",
    "                'locked' : 'CommentsLocked',\n",
    "                'post_hint' : 'PostHint',\n",
    "                'preview' : 'Preview',\n",
    "                'is_crosspostable' : 'IsCrosspostable',\n",
    "                'is_reddit_media_domain' : 'IsRedditMediaDomain',\n",
    "                'is_video' : 'IsVideo',\n",
    "                'num_crossposts' : 'CrosspostsNumber', \n",
    "                'pinned' : 'Pinned',\n",
    "                'crosspost_parent' : 'CrosspostParent',\n",
    "                'crosspost_parent_list' : 'CrosspostParentList',\n",
    "                'is_meta' : 'IsMeta',\n",
    "                'is_original_content' : 'IsOriginal',\n",
    "                'media_only' : 'OnlyMedia', \n",
    "                'subreddit_subscribers' : 'SubRedditSubscribers',\n",
    "                'media_metadata' : 'MediaMetadata', \n",
    "                'upvote_ratio' : 'UpvoteRatio', \n",
    "                'gallery_data' : 'GalleryData', \n",
    "                'is_gallery' : 'IsGallery', \n",
    "                'author_cakeday' : 'AuthorBirthdate',\n",
    "                'edited' : 'Edited', \n",
    "                'view_count' : 'ViewCount', \n",
    "                'author_id' : 'AuthorID',\n",
    "                'og_description' : 'OGDescription',\n",
    "                'og_title' : 'OGTitle'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rename columns using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_tidy_df = posts_df.rename(columns = column_names)\n",
    "# Check to see if columns have been renamed\n",
    "posts_tidy_df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reorder columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_tidy_df = posts_tidy_df[['Subreddit', 'SubredditID', 'PostTitle', 'PostID', 'PostTime', 'Username', 'Upvotes', 'CommentNumber', 'ImageDomain', 'ImageURL', 'UserCreatedTime', 'AuthorName', 'Permalink', 'Link', 'IsTextPost', 'PostText', 'EmbeddedMedia', 'Thumbnail', 'NSFW']]\n",
    "posts_tidy_df = posts_tidy_df[['Subreddit', 'SubredditID', 'PostTitle', 'PostID', 'PostTime', 'Username', 'Upvotes', 'CommentNumber', 'ImageDomain', 'ImageURL', 'AuthorName', 'Permalink', 'IsTextPost', 'PostText', 'EmbeddedMedia', 'Thumbnail', 'NSFW']]\n",
    "                                       \n",
    "\n",
    "#posts_reordered_df = posts_renamed_df[['Subreddit', 'SubredditID', 'PostTitle', 'PostID', 'PostTime', 'Username', 'ViewCount', 'Upvotes', 'UpvoteRatio', 'CommentNumber', 'Edited', 'OGDescription', 'OGTitle', 'ImageDomain', 'ImageURL', 'Permalink', 'Link', 'IsTextPost', 'PostText', 'UserCreatedTime', 'AuthorID', 'AuthorName', 'AuthorBirthdate', 'IsVideo', 'IsMeta', 'IsOriginal', 'IsGallery', 'GalleryData', 'IsRedditMediaDomain', 'IsCrosspostable', 'CrosspostsNumber', 'CrosspostParent', 'CrosspostParentList', 'SubRedditSubscribers', 'OnlyMedia', 'MediaMetadata', 'EmbeddedMedia', 'SecureEmbeddedMedia', 'Media', 'SecureMedia', 'Thumbnail', 'Stickied', 'Pinned', 'PostHint', 'Preview', 'CommentsLocked', 'NSFW']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert time stamp from UNIX to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_tidy_df['PostTime'] = pd.to_datetime(posts_tidy_df['PostTime'], utc=True, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix image URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_tidy_df = posts_tidy_df.reindex(columns = posts_tidy_df.columns.tolist() + ['NewURL']) #create column for fixed urls\n",
    "\n",
    "for index, row in posts_tidy_df.iterrows():\n",
    "    if row['ImageDomain'] == 'flickr.com':\n",
    "        print(row['ImageURL'])\n",
    "        r = requests.get(row['ImageURL'])\n",
    "        soup = bs(r.content)\n",
    "        images = re.findall(r'(\\/\\/live\\.staticflickr\\.com\\/[0-9][0-9][0-9][0-9][0-9]\\/[a-zA-Z0-9_]+\\.(?:png|jpg|jpeg|gif|png|svg))', str(soup))\n",
    "        \n",
    "        for image in images:\n",
    "            image_url = image\n",
    "            break\n",
    "        print(image_url)\n",
    "        posts_tidy_df.at[index, 'NewURL'] = 'https:' + image_url\n",
    "    elif row['ImageDomain'] == 'imgur.com':\n",
    "        posts_tidy_df.at[index, 'NewURL'] = re.sub(r'http://imgur.com', 'http://i.imgur.com', row['ImageURL']) + '.jpg'\n",
    "    elif row['ImageDomain'] == 'i.imgur.com':\n",
    "        posts_tidy_df.at[index, 'NewURL'] = row['ImageURL']\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data frame and images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "posts_tidy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data frame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/Skrubbe/Documents/GitHub/FlickrFaves/Data/Reddit_'+ subreddit + '_' + search_time + '.csv'\n",
    "posts_tidy_df.to_csv(filename, header=True, index=False, columns=list(posts_tidy_df.axes[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save images from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save images from data frame URL column\n",
    "root_folder = 'C:/Users/Skrubbe/Documents/GitHub/FlickrFaves/Data/Reddit/'\n",
    "\n",
    "def download(row):\n",
    "   print(row['PostTitle'])\n",
    "   filename = root_folder + subreddit + '_' + row[3] + '.jpg'\n",
    "   \n",
    "   # create folder if it doesn't exist\n",
    "   os.makedirs(os.path.dirname(filename), exist_ok = True)\n",
    "   \n",
    "   if pd.isnull(row.NewURL) :\n",
    "       url = row.ImageURL\n",
    "   else :\n",
    "       url = row.NewURL\n",
    "   \n",
    "   \n",
    "   print(f\"Downloading {url} to {filename}\")\n",
    "   \n",
    "   r = requests.get(url, allow_redirects=True)\n",
    "   print(\"lol\")\n",
    "   with open(filename, 'wb') as f:\n",
    "       f.write(r.content)\n",
    "posts_tidy_df.apply(download, axis=1)\n",
    "print(\"lul\")\n",
    "\n",
    "# try:\n",
    "#     posts_tidy_df.apply(download, axis=1)\n",
    "#     print(\"lul\")\n",
    "# except:\n",
    "#     pass\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning and annotating features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> this might be useful later on to create a list of features mentioned in the text for each picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove brackets and other characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_clean_df = posts_tidy_df.rename(columns = column_names)\n",
    "posts_clean_df['PostTitle'].replace(to_replace=\"\\[(.*?)\\]\", value=\"\", regex=True, inplace=True) \n",
    "posts_clean_df['PostTitle'].replace(to_replace=\"\\(\\d*?\\s*[\\u00D7?x?]\\s*\\d*?\\)\", value=\"\", regex=True, inplace=True)\n",
    "posts_clean_df['PostTitle'].replace(to_replace=\"\\(\", value=\"\", regex=True, inplace=True)\n",
    "posts_clean_df['PostTitle'].replace(to_replace=\"\\)\", value=\"\", regex=True, inplace=True)\n",
    "posts_clean_df['PostTitle'].replace(to_replace=\"-\", value=\"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_udpipe.download(\"en\")\n",
    "nlp = spacy_udpipe.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create new data frame for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Sentence', 'Text ID', 'IDX', 'Text', 'Lemma', 'POS', 'Form', 'Dependency', 'Sentiment'] \n",
    "posts_annotated_df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create empty lists to store token values in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = []\n",
    "i = []\n",
    "idx = []\n",
    "word = []\n",
    "lemma = []\n",
    "pos = []\n",
    "tag = []\n",
    "dep = []\n",
    "sentiment = []\n",
    "form = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize post titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in posts_clean_df.iterrows():\n",
    "    text = row['PostTitle']\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        #print('Sentence:' + token.sent)\n",
    "        sent.append(token.sent)\n",
    "        i.append(token.i)\n",
    "        idx.append(token.idx)\n",
    "        word.append(token.text)\n",
    "        lemma.append(token.lemma_)\n",
    "        pos.append(token.pos_)\n",
    "        form.append(token.morph.get(\"VerbForm\"))\n",
    "        tag.append(token.tag_)\n",
    "        dep.append(token.dep_)\n",
    "        sentiment.append(token.sentiment)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add token annotations to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_annotated_df['Sentence'] = sent\n",
    "posts_annotated_df['Text ID'] = i\n",
    "posts_annotated_df['Text'] = word\n",
    "posts_annotated_df['Lemma'] = lemma\n",
    "posts_annotated_df['POS'] = pos\n",
    "posts_annotated_df['VerbForm'] = form\n",
    "posts_annotated_df['Dependency'] = dep\n",
    "posts_annotated_df['IDX'] = idx\n",
    "posts_annotated_df['Sentiment'] = sentiment\n",
    "posts_annotated_df['VerbForm'] = posts_annotated_df['VerbForm'].str[0]\n",
    "\n",
    "print(posts_annotated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save annotations as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/acali/OneDrive - Danmarks Tekniske Universitet/Code/Reddit_Annotated_'+ subreddit + '_' + search_time + '.csv'\n",
    "posts_annotated_df.to_csv(filename, header=True, index=False, columns=list(posts_annotated_df.axes[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_df = posts_annotated_df[posts_annotated_df['POS'].str.contains(\"NOUN|PROPNOUN\")]\n",
    "features_df = nouns_df[nouns_df['Dependency'].str.contains('ROOT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = features_df['Text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data frame with features and subreddit name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CES_features = pd.DataFrame()\n",
    "CES_features['Features'] = features_list\n",
    "CES_features['Subreddit'] = subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save features as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_CES_features_updated.to_csv(features_filename, header=True, index=False, columns=list(All_CES_features_updated.axes[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "977acd824d1c8ea39063d70b546b655f6c17320f76a23d6f8f3ee345ce1dbf12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
